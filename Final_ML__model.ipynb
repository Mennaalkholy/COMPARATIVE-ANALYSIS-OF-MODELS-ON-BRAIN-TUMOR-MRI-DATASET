{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2645886,
          "sourceType": "datasetVersion",
          "datasetId": 1608934
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52koIxEGqLlX",
        "outputId": "dbdbc5b3-dfbf-4660-ba1f-e3317964db1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOKIasLaqLc-",
        "outputId": "cbda89d6-ee97-46da-9a57-67b0496b9c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joA5Fxm7qLPB",
        "outputId": "f44bbefa-8d9b-4b2b-d7b3-106b5e25cf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\")"
      ],
      "metadata": {
        "id": "woZBA5eY20Sd",
        "outputId": "a44a961f-12bc-476b-f6b4-c6500a2aefe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: reemramadannegm\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "Downloading brain-tumor-mri-dataset.zip to ./brain-tumor-mri-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149M/149M [00:00<00:00, 1.23GB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tempfile import TemporaryDirectory\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-16T02:15:51.972147Z",
          "iopub.execute_input": "2025-04-16T02:15:51.972595Z",
          "iopub.status.idle": "2025-04-16T02:16:11.256607Z",
          "shell.execute_reply.started": "2025-04-16T02:15:51.972552Z",
          "shell.execute_reply": "2025-04-16T02:16:11.255955Z"
        },
        "id": "312dbedf-1c85-48a2-a2b0-5c0591261c7f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/brain-tumor-mri-dataset'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {device} device\")\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-16T02:16:11.257642Z",
          "iopub.execute_input": "2025-04-16T02:16:11.25817Z",
          "iopub.status.idle": "2025-04-16T02:16:11.334422Z",
          "shell.execute_reply.started": "2025-04-16T02:16:11.258146Z",
          "shell.execute_reply": "2025-04-16T02:16:11.333434Z"
        },
        "id": "9d1bb103-d8eb-49df-99b0-8eb6801b5a30",
        "outputId": "60039bae-ab0d-42e5-f6eb-c5a38b1d4eef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-16T02:16:11.336633Z",
          "iopub.execute_input": "2025-04-16T02:16:11.336956Z",
          "iopub.status.idle": "2025-04-16T02:16:11.36667Z",
          "shell.execute_reply.started": "2025-04-16T02:16:11.336925Z",
          "shell.execute_reply": "2025-04-16T02:16:11.365961Z"
        },
        "id": "6c14b4ea-4b3a-4d4a-877e-0a81de1b2455"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "def tranfer_learning(model_name):\n",
        "    if model_name == 'efficientnet_b2':\n",
        "        model = models.efficientnet_b2(pretrained=True)\n",
        "        num_ft = model.classifier[1].in_features\n",
        "        model.classifier[1] = nn.Linear(num_ft, 4)\n",
        "        model = model.to(device)\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-16T02:16:55.820667Z",
          "iopub.execute_input": "2025-04-16T02:16:55.82088Z",
          "iopub.status.idle": "2025-04-16T02:16:55.826003Z",
          "shell.execute_reply.started": "2025-04-16T02:16:55.820862Z",
          "shell.execute_reply": "2025-04-16T02:16:55.825245Z"
        },
        "id": "5a6ad1e3-ba5a-48c4-bb42-5d899f6a6fe7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model, criterion, optimizer, scheduler, num_epochs=15):\n",
        "    since = time.time()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['Training', 'Testing']:\n",
        "            if phase == 'Training':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'Training'):\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'Training':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'Training':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'Testing' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model.state_dict(), 'full_model.pth')\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best Testing Acc: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(torch.load('full_model.pth'))\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-16T02:16:55.826814Z",
          "iopub.execute_input": "2025-04-16T02:16:55.827067Z",
          "iopub.status.idle": "2025-04-16T02:16:55.840946Z",
          "shell.execute_reply.started": "2025-04-16T02:16:55.827039Z",
          "shell.execute_reply": "2025-04-16T02:16:55.840129Z"
        },
        "id": "a22e41bd-7f9e-43b0-816f-3be2c9af5634"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def final_test_report(model):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['Testing']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"Final Test Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-16T02:16:55.84307Z",
          "iopub.execute_input": "2025-04-16T02:16:55.84333Z",
          "iopub.status.idle": "2025-04-16T03:21:17.664917Z",
          "shell.execute_reply.started": "2025-04-16T02:16:55.843309Z",
          "shell.execute_reply": "2025-04-16T03:21:17.66417Z"
        },
        "id": "f478dab0-e67c-4d16-b3e9-01992457efdb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = tranfer_learning('efficientnet_b2')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, gamma=0.1)\n",
        "model = train_and_validate(model, criterion, optimizer, exp_lr_scheduler, num_epochs=5)\n",
        "final_test_report(model)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "e50951c1-b3eb-4563-bcc6-6f14efd9fc06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108430a5-efba-48f9-b131-846c36ccaf14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "Training Loss: 0.3333 Acc: 0.8871\n",
            "Testing Loss: 0.2310 Acc: 0.9146\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "Training Loss: 0.1610 Acc: 0.9480\n",
            "Testing Loss: 0.1117 Acc: 0.9588\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "Training Loss: 0.0979 Acc: 0.9697\n",
            "Testing Loss: 0.0548 Acc: 0.9840\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "Training Loss: 0.0884 Acc: 0.9720\n",
            "Testing Loss: 0.8782 Acc: 0.8528\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "Training Loss: 0.0824 Acc: 0.9744\n",
            "Testing Loss: 0.0732 Acc: 0.9779\n",
            "\n",
            "Training complete in 5m 59s\n",
            "Best Testing Acc: 0.9840\n",
            "Final Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma       0.95      0.99      0.97       300\n",
            "  meningioma       0.98      0.96      0.97       306\n",
            "     notumor       1.00      0.98      0.99       405\n",
            "   pituitary       0.99      0.99      0.99       300\n",
            "\n",
            "    accuracy                           0.98      1311\n",
            "   macro avg       0.98      0.98      0.98      1311\n",
            "weighted avg       0.98      0.98      0.98      1311\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'full_model.pth')\n"
      ],
      "metadata": {
        "id": "838YKRAHzGoL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}